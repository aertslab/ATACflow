{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VSN Pipelines: pycisTopic QC report\n",
    "\n",
    "scATAC-seq quality control and cell calling from pycisTopic (https://github.com/aertslab/pycisTopic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycisTopic\n",
    "pycisTopic.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybiomart as pbm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from multiprocessing import Pool # for kde multithreading calculation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.loads(WORKFLOW_PARAMETERS)\n",
    "\n",
    "sample_ids = SAMPLES.split(',')\n",
    "\n",
    "print(f\"SAMPLES: {sample_ids}\")\n",
    "print(f\"pycisTopic parameters: {json.dumps(params, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "infile = open(METADATAPKL, 'rb')\n",
    "metadata_bc_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load profile data\n",
    "infile = open(PROFDATAPKL, 'rb')\n",
    "profile_data_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.qc import plot_sample_metrics\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-sample metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_id in profile_data_dict:\n",
    "    plot_sample_metrics({sample_id: profile_data_dict[sample_id]},\n",
    "               profile_list=['barcode_rank_plot', 'insert_size_distribution', 'profile_tss', 'frip'],\n",
    "               insert_size_distriubtion_xlim=[0,600],\n",
    "               ncol=4,\n",
    "               cmap='tab20',\n",
    "               plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined sample metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_metrics(profile_data_dict,\n",
    "           profile_list=['barcode_rank_plot', 'insert_size_distribution', 'profile_tss', 'frip'],\n",
    "           insert_size_distriubtion_xlim=[0,600],\n",
    "           ncol=4,\n",
    "           cmap='tab20',\n",
    "           plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frag_qc(x, y, \n",
    "                 ax,\n",
    "                 x_thr_min=None, x_thr_max=None,\n",
    "                 y_thr_min=None, y_thr_max=None,\n",
    "                 ylab=None,\n",
    "                 xlab=\"Number of (unique) fragments\",\n",
    "                 cmap='viridis',\n",
    "                 density_overlay=False,\n",
    "                 s=10,\n",
    "                 marker='+',\n",
    "                 c='#343434',\n",
    "                 xlim=None,\n",
    "                 ylim=None,\n",
    "                 **kwargs\n",
    "                ):\n",
    "    assert all(x.index == y.index)\n",
    "    barcodes = x.index.values\n",
    "    if density_overlay:\n",
    "        xy = np.vstack([np.log(x),y])\n",
    "        \n",
    "        ## here i add multithreading to the kde calculation\n",
    "\n",
    "        # Create definition.\n",
    "        def calc_kernel(xy):\n",
    "            return gaussian_kde(xy)(xy)\n",
    "\n",
    "\n",
    "        # Choose number of cores and split input array.\n",
    "        cores = 8\n",
    "        torun = np.array_split(xy, cores, axis=1)\n",
    "\n",
    "        # Calculate\n",
    "        pool = Pool(processes=cores)\n",
    "        results = pool.map(calc_kernel, torun)\n",
    "        z = np.concatenate(results)        \n",
    "        \n",
    "        ### end of multithreading part\n",
    "        idx = z.argsort()\n",
    "        x, y, z, barcodes = x[idx], y[idx], z[idx], barcodes[idx]\n",
    "    else:\n",
    "        z=c\n",
    "    barcodes_to_keep=[]\n",
    "    sp=ax.scatter(x, y, c=z, s=s, edgecolors=None, marker=marker, cmap=cmap, **kwargs)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim[0], xlim[1])\n",
    "    # thresholds:\n",
    "    if x_thr_min is not None:    \n",
    "        ax.axvline(x=x_thr_min, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[x>x_thr_min])\n",
    "    if x_thr_max is not None:    \n",
    "        ax.axvline(x=x_thr_max, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[x<x_thr_max])\n",
    "    if y_thr_min is not None:    \n",
    "        ax.axhline(y=y_thr_min, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[y>y_thr_min])\n",
    "    if y_thr_max is not None:    \n",
    "        ax.axhline(y=y_thr_max, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[y<y_thr_max])\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xmargin(0.01)\n",
    "    ax.set_ymargin(0.01)\n",
    "    ax.set_xlabel(xlab,fontsize=10)\n",
    "    ax.set_ylabel(ylab,fontsize=10)\n",
    "    #return barcodes_to_keep\n",
    "    if len(barcodes_to_keep)>0:\n",
    "        return list(set.intersection(*map(set, barcodes_to_keep)))\n",
    "    else:\n",
    "        return barcodes\n",
    "\n",
    "def histogram(array, nbins=100):\n",
    "    \"\"\"\n",
    "    Draw histogram from distribution and identify centers.\n",
    "    Parameters\n",
    "    ---------\n",
    "    array: `class::np.array`\n",
    "            Scores distribution\n",
    "    nbins: int\n",
    "            Number of bins to use in the histogram\n",
    "    Return\n",
    "    ---------\n",
    "    float\n",
    "            Histogram values and bin centers.\n",
    "    \"\"\"\n",
    "    array = array.ravel().flatten()\n",
    "    hist, bin_edges = np.histogram(array, bins=nbins, range=None)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.\n",
    "    return hist, bin_centers\n",
    "\n",
    "\n",
    "def threshold_otsu(array, nbins=100):\n",
    "    \"\"\"\n",
    "    Apply Otsu threshold on topic-region distributions [Otsu, 1979].\n",
    "    Parameters\n",
    "    ---------\n",
    "    array: `class::np.array`\n",
    "            Array containing the region values for the topic to be binarized.\n",
    "    nbins: int\n",
    "            Number of bins to use in the binarization histogram\n",
    "    Return\n",
    "    ---------\n",
    "    float\n",
    "            Binarization threshold.\n",
    "    Reference\n",
    "    ---------\n",
    "    Otsu, N., 1979. A threshold selection method from gray-level histograms. IEEE transactions on systems, man, and\n",
    "    cybernetics, 9(1), pp.62-66.\n",
    "    \"\"\" \n",
    "    hist, bin_centers = histogram(array, nbins)\n",
    "    hist = hist.astype(float)\n",
    "    # Class probabilities for all possible thresholds\n",
    "    weight1 = np.cumsum(hist)\n",
    "    weight2 = np.cumsum(hist[::-1])[::-1]\n",
    "    # Class means for all possible thresholds\n",
    "    mean1 = np.cumsum(hist * bin_centers) / weight1\n",
    "    mean2 = (np.cumsum((hist * bin_centers)[::-1]) / weight2[::-1])[::-1]\n",
    "    # Clip ends to align class 1 and class 2 variables:\n",
    "    # The last value of ``weight1``/``mean1`` should pair with zero values in\n",
    "    # ``weight2``/``mean2``, which do not exist.\n",
    "    variance12 = weight1[:-1] * weight2[1:] * (mean1[:-1] - mean2[1:]) ** 2\n",
    "    idx = np.argmax(variance12)\n",
    "    threshold = bin_centers[:-1][idx]\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract filter thresholds from Nextflow parameters\n",
    "filter_frags_lower = {}\n",
    "filter_frags_upper = {}\n",
    "filter_tss_lower = {}\n",
    "filter_tss_upper = {}\n",
    "filter_frip_lower = {}\n",
    "filter_frip_upper = {}\n",
    "filter_dup_rate_lower = {}\n",
    "filter_dup_rate_upper = {}\n",
    "\n",
    "def float_or_none(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def extract_sample_specific_param(filter_dict, sample_id, param_key):\n",
    "    if type(params['call_cells'][param_key]) is dict:\n",
    "        if sample_id in params['call_cells'][param_key]:\n",
    "            filter_dict[sample_id] = float_or_none(params['call_cells'][param_key][sample_id])\n",
    "        else:\n",
    "            try:\n",
    "                filter_dict[sample_id] = float_or_none(params['call_cells'][param_key]['default'])\n",
    "            except KeyError:\n",
    "                print(f\"WARNING: Missing 'default' key in the sample parameters list. Filter for '{param_key}' will be missing for sample '{sample_id}'.\")\n",
    "                filter_dict[sample_id] = None\n",
    "    else:\n",
    "        filter_dict[sample_id] = float_or_none(params['call_cells'][param_key])\n",
    "    return filter_dict\n",
    "\n",
    "for s in sample_ids:\n",
    "    filter_frags_lower = extract_sample_specific_param(filter_frags_lower, s, 'filter_frags_lower')\n",
    "    filter_frags_upper = extract_sample_specific_param(filter_frags_upper, s, 'filter_frags_upper')\n",
    "    #\n",
    "    filter_tss_lower = extract_sample_specific_param(filter_tss_lower, s, 'filter_tss_lower')\n",
    "    filter_tss_upper = extract_sample_specific_param(filter_tss_upper, s, 'filter_tss_upper')\n",
    "    #\n",
    "    filter_frip_lower = extract_sample_specific_param(filter_frip_lower, s, 'filter_frip_lower')\n",
    "    filter_frip_upper = extract_sample_specific_param(filter_frip_upper, s, 'filter_frip_upper')\n",
    "    #\n",
    "    filter_dup_rate_lower = extract_sample_specific_param(filter_dup_rate_lower, s, 'filter_dup_rate_lower')\n",
    "    filter_dup_rate_upper = extract_sample_specific_param(filter_dup_rate_upper, s, 'filter_dup_rate_upper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cell filters:\n",
    "print(f\"Filter parameters:\")\n",
    "print(f\"filter_frags_lower: {json.dumps(filter_frags_lower, indent=4)}\")\n",
    "print(f\"filter_frags_upper: {json.dumps(filter_frags_upper, indent=4)}\")\n",
    "print(f\"filter_tss_lower: {json.dumps(filter_tss_lower, indent=4)}\")\n",
    "print(f\"filter_tss_upper: {json.dumps(filter_tss_upper, indent=4)}\")\n",
    "print(f\"filter_frip_lower: {json.dumps(filter_frip_lower, indent=4)}\")\n",
    "print(f\"filter_frip_upper: {json.dumps(filter_frip_upper, indent=4)}\")\n",
    "print(f\"filter_dup_rate_lower: {json.dumps(filter_dup_rate_lower, indent=4)}\")\n",
    "print(f\"filter_dup_rate_upper: {json.dumps(filter_dup_rate_upper, indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Otsu thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_kde = True\n",
    "detailed_title=params['call_cells']['use_detailed_title_on_scatterplot']\n",
    "s=4\n",
    "bc_passing_filters = {}\n",
    "for k,v in metadata_bc_dict.items():\n",
    "\n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(12,4), dpi=150 )\n",
    "    \n",
    "    # calculate thresholds using otsu:\n",
    "    x_arr = metadata_bc_dict[k]['Log_total_nr_frag']\n",
    "    x_threshold = threshold_otsu(x_arr, 5000)\n",
    "    x_threshold = 10**x_threshold\n",
    "\n",
    "    y_arr = metadata_bc_dict[k]['TSS_enrichment']\n",
    "    y_arr_cutoff = threshold_otsu(y_arr, 5000)\n",
    "    y_threshold = threshold_otsu(y_arr_cutoff, 5000)\n",
    "    \n",
    "    # plot everything\n",
    "    p1_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['TSS_enrichment'],\n",
    "        ylab = 'TSS Enrichment',\n",
    "        s=s,\n",
    "        x_thr_min=x_threshold,\n",
    "        y_thr_min=y_threshold,\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax1\n",
    "    )\n",
    "    p2_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['FRIP'],\n",
    "        x_thr_min=x_threshold,\n",
    "        ylab = 'FRIP',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax2\n",
    "    )\n",
    "    p3_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['Dupl_rate'],\n",
    "        x_thr_min=x_threshold,\n",
    "        ylab = 'Duplicate rate per cell',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax3\n",
    "    )\n",
    "    bc_passing_filters[k] = list(set(p1_cells) & set(p2_cells) & set(p3_cells))\n",
    "    if detailed_title:\n",
    "        med_nf = metadata_bc_dict[k].loc[bc_passing_filters[k],'Unique_nr_frag'].median()\n",
    "        med_tss = metadata_bc_dict[k].loc[bc_passing_filters[k],'TSS_enrichment'].median()\n",
    "        med_frip = metadata_bc_dict[k].loc[bc_passing_filters[k],'FRIP'].median()\n",
    "        title = f\"{k}: Kept {len(bc_passing_filters[k])} cells using Otsu filtering. Median(fragments): {med_nf:.0f}. Median(TSS Enrichment): {med_tss:.2f}). Median FRIP: {med_frip:.2f}\\nUsed a minimum of {x_threshold} fragments and TSS enrichment of {y_threshold})\"\n",
    "    else:\n",
    "        title = k\n",
    "    fig.suptitle(title, x=0.5, y=0.95, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"qc_otsu_{k}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bc_passing_filters_otsu.pkl', 'wb') as f:\n",
    "  pickle.dump(bc_passing_filters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T06:43:55.150843Z",
     "iopub.status.busy": "2022-05-17T06:43:55.150438Z",
     "iopub.status.idle": "2022-05-17T06:43:55.165238Z",
     "shell.execute_reply": "2022-05-17T06:43:55.164752Z"
    },
    "papermill": {
     "duration": 0.050256,
     "end_time": "2022-05-17T06:43:55.165359",
     "exception": false,
     "start_time": "2022-05-17T06:43:55.115103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write all cell barcodes selected by filtering\n",
    "if not os.path.exists('selected_barcodes'):\n",
    "    os.makedirs('selected_barcodes')\n",
    "    \n",
    "for k,v in bc_passing_filters.items():\n",
    "    pd.DataFrame(v).to_csv('selected_barcodes/'+k+'_otsu.cell_barcodes.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With predefined thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_kde = params['call_cells']['use_density_coloring_on_scatterplot']\n",
    "detailed_title=params['call_cells']['use_detailed_title_on_scatterplot']\n",
    "s=4\n",
    "bc_passing_filters = {}\n",
    "for k,v in metadata_bc_dict.items():\n",
    "\n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(12,4), dpi=150 )\n",
    "    p1_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['TSS_enrichment'],\n",
    "        ylab = 'TSS Enrichment',\n",
    "        s=s,\n",
    "        x_thr_min=filter_frags_lower[k],\n",
    "        y_thr_min=filter_tss_lower[k],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax1\n",
    "    )\n",
    "    p2_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['FRIP'],\n",
    "        x_thr_min=filter_frags_lower[k],\n",
    "        ylab = 'FRIP',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax2\n",
    "    )\n",
    "    p3_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['Dupl_rate'],\n",
    "        x_thr_min=filter_frags_lower[k],\n",
    "        ylab = 'Duplicate rate per cell',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax3\n",
    "    )\n",
    "    bc_passing_filters[k] = list(set(p1_cells) & set(p2_cells) & set(p3_cells))\n",
    "    if detailed_title:\n",
    "        med_nf = metadata_bc_dict[k].loc[bc_passing_filters[k],'Unique_nr_frag'].median()\n",
    "        med_tss = metadata_bc_dict[k].loc[bc_passing_filters[k],'TSS_enrichment'].median()\n",
    "        title = f\"{k}: Kept {len(bc_passing_filters[k])} cells. Median(fragments): {med_nf:.0f}. Median(TSS Enrichment): {med_tss:.2f}). Median FRIP: {med_frip:.2f}.\"\n",
    "    else:\n",
    "        title = k\n",
    "    fig.suptitle(title, x=0.5, y=0.95, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bc_passing_filters.pkl', 'wb') as f:\n",
    "  pickle.dump(bc_passing_filters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all barcodes selected in compute_qc_stats (with nFrag>x)\n",
    "if not os.path.exists('selected_barcodes_nFrag'):\n",
    "    os.makedirs('selected_barcodes_nFrag')\n",
    "    \n",
    "for k,v in metadata_bc_dict.items():\n",
    "    pd.DataFrame(v.index).to_csv('selected_barcodes_nFrag/'+k+'.barcodes_nFrag_thr.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all cell barcodes selected by filtering\n",
    "if not os.path.exists('selected_barcodes'):\n",
    "    os.makedirs('selected_barcodes')\n",
    "    \n",
    "for k,v in bc_passing_filters.items():\n",
    "    pd.DataFrame(v).to_csv('selected_barcodes/'+k+'.cell_barcodes.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pycisTopic barcode metrics plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.qc import plot_barcode_metrics\n",
    "from pycisTopic.utils import fig2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_or_log10(x):\n",
    "    return None if x is None else np.log10(x)\n",
    "\n",
    "for k,v in metadata_bc_dict.items():\n",
    "\n",
    "    FRIP_NR_FRAG_fig = plot_barcode_metrics(metadata_bc_dict[k],\n",
    "                                            var_x='Log_unique_nr_frag',\n",
    "                                            var_y='FRIP',\n",
    "                                            min_x=none_or_log10(filter_frags_lower[k]),\n",
    "                                            max_x=none_or_log10(filter_frags_upper[k]),\n",
    "                                            min_y=filter_frip_lower[k],\n",
    "                                            max_y=filter_frip_upper[k],\n",
    "                                            return_cells=False,\n",
    "                                            return_fig=True,\n",
    "                                            plot=False,\n",
    "                                            )\n",
    "\n",
    "    TSS_NR_FRAG_fig = plot_barcode_metrics(metadata_bc_dict[k],\n",
    "                                           var_x='Log_unique_nr_frag',\n",
    "                                           var_y='TSS_enrichment',\n",
    "                                           min_x=none_or_log10(filter_frags_lower[k]),\n",
    "                                           max_x=none_or_log10(filter_frags_upper[k]),\n",
    "                                           min_y=filter_tss_lower[k],\n",
    "                                           max_y=filter_tss_upper[k],\n",
    "                                           return_cells=False,\n",
    "                                           return_fig=True,\n",
    "                                           plot=False\n",
    "                                           )\n",
    "\n",
    "    DR_NR_FRAG_fig = plot_barcode_metrics(metadata_bc_dict[k],\n",
    "                                          var_x='Log_unique_nr_frag',\n",
    "                                          var_y='Dupl_rate',\n",
    "                                          min_x=none_or_log10(filter_frags_lower[k]),\n",
    "                                          max_x=none_or_log10(filter_frags_upper[k]),\n",
    "                                          min_y=filter_dup_rate_lower[k],\n",
    "                                          max_y=filter_dup_rate_upper[k],\n",
    "                                          return_cells=False,\n",
    "                                          return_fig=True,\n",
    "                                          plot=False\n",
    "                                          )\n",
    "    fig=plt.figure(figsize=(30,7.5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    img = fig2img(TSS_NR_FRAG_fig)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    img = fig2img(FRIP_NR_FRAG_fig)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    img = fig2img(DR_NR_FRAG_fig)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    fig.suptitle(k, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.DataFrame([\n",
    "    list(bc_passing_filters),\n",
    "    [ len(bc_passing_filters[x]) for x in bc_passing_filters ]\n",
    "\n",
    "]).T\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,4), dpi=150 )\n",
    "g=sns.barplot(x=1, y=0, data=tp,\n",
    "           palette='tab20')\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()    # get bar length\n",
    "    ax.text(width,           # set the text at 1 unit right of the bar\n",
    "            p.get_y() + p.get_height() / 2, # get Y coordinate + X coordinate / 2\n",
    "            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n",
    "            ha = 'right',   # horizontal alignment\n",
    "            va = 'center')  # vertical alignment\n",
    "ax.set_xlabel(\"Number of cells\",fontsize=10)\n",
    "ax.set_ylabel(\"\",fontsize=10)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker as mticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats_violin(\n",
    "    data,\n",
    "    ax,\n",
    "    var = 'Unique_nr_frag',\n",
    "    ylab='Number of (unique) fragments',\n",
    "    xlab='',\n",
    "    logscale=True,\n",
    "    **kwargs\n",
    "    ):\n",
    "\n",
    "    tp = []\n",
    "    for k,v in data.items():\n",
    "        tmp = pd.DataFrame(np.log10(data[k][var])) if logscale else pd.DataFrame(data[k][var])\n",
    "        tmp['Sample'] = k\n",
    "        tp.append(tmp)\n",
    "    tp = pd.concat(tp, join='outer', axis=0)\n",
    "\n",
    "    yrange = [ int(math.floor(tp[var].min())), int(math.ceil(tp[var].max())) ]\n",
    "    \n",
    "    g = sns.violinplot(data=tp, x='Sample', y=var,\n",
    "                       dodge=True,\n",
    "                       linewidth=0.5,\n",
    "                       inner='quartiles',\n",
    "                       ax=ax, kind='kde',\n",
    "                       **kwargs)\n",
    "    \n",
    "    ax.set_xlabel(xlab,fontsize=10)\n",
    "    ax.set_ylabel(ylab,fontsize=10)\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=15, ha='right', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #palette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    ylab='log10 Number of (unique) fragments',\n",
    "    var='Unique_nr_frag')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #palette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    logscale=False,\n",
    "    ylab='TSS enrichment',\n",
    "    var='TSS_enrichment')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #palette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    logscale=False,\n",
    "    ylab='Duplicate rate',\n",
    "    var='Dupl_rate')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #alette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    logscale=False,\n",
    "    ylab='FRIP',\n",
    "    var='FRIP')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
